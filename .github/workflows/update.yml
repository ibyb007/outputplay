name: Update Filtered & Categorized JTV M3U → Private Gist

on:
  schedule:
    - cron: '10 */3 * * *'      # Every 3 hours at :10 past the hour (UTC)

  workflow_dispatch:

jobs:
  generate-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Generate filtered & categorized jtv.m3u → Gist
        env:
          SOURCE_URL: ${{ secrets.SOURCE_URL }}
          GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
          GIST_ID:    ${{ secrets.GIST_ID }}
        run: |
          python3 - << 'EOF'
          import requests
          import os
          from datetime import datetime

          SOURCE_URL = os.getenv("SOURCE_URL")
          GIST_TOKEN = os.getenv("GIST_TOKEN")
          GIST_ID    = os.getenv("GIST_ID")
          OUTPUT_FILE_NAME = "jtv.m3u"
          USER_AGENT = "plaYtv/7.1.3 (Linux;Android 13) ygx/824.1 ExoPlayerLib/824.0"

          if not all([SOURCE_URL, GIST_TOKEN, GIST_ID]):
              print("Missing required secrets")
              exit(1)

          print(f"Fetching from {SOURCE_URL}")
          try:
              resp = requests.get(SOURCE_URL, timeout=20)
              resp.raise_for_status()
              data = resp.json()
              channels = data if isinstance(data, list) else data.get("channels", []) or []
          except Exception as e:
              print(f"Fetch/parse error: {e}")
              exit(1)

          if not channels:
              print("No channels found")
              exit(1)

          # Expanded exclusion keywords
          exclude_patterns = [
              # Previous regional + devotional + educational
              "tamil", "sun", "vijay", "kalaignar", "raj", "telugu", "gemini", "etv", "maa", "zeetelugu",
              "kannada", "colorskannada", "sudeep", "udaya", "suvarna", "gujarati", "sabgujarati",
              "malayalam", "mazhavil", "surya", "punjabi", "ptc", "mh1", "ziyara",
              "devotional", "bhakti", "santvani", "iskcon", "sadhguru", "astrology", "shri", "ramayan", "mahadev",
              "educational", "gyan", "gyandarshan", "vedanta", "vande", "swayam", "pm e", "evidya", "pm e-vidya", "prabha",
              # New exclusions
              "bhojpuri", "zeebhojpuri", "big ganga", "maiboli", "marathi", "dd", "doordarshan", "dd national", "dd news", "dd sports", "dd kisan", "dd retro"
          ]

          def get_category(name):
              name_lower = name.lower()
              
              # Bengali (includes Colors Bangla HD as requested)
              if any(kw in name_lower for kw in ["bangla", "jalsha", "aath", "ananda", "tv9 bangla", "news18 bangla", "abp ananda", "zee bangla", "star jalsha", "colors bangla", "24 ghanta"]):
                  return "Bengali"
              
              # Assamese
              if any(kw in name_lower for kw in ["assam", "dy 365", "news18 assam", "prag news", "rang", "jonack", "rengoni", "pratidin time", "time8", "north east"]):
                  return "Assamese"
              
              # Kids (new category)
              if any(kw in name_lower for kw in ["nick", "nickelodeon", "cartoon network", "pogo", "hungama", "disney", "sonic", "discovery kids", "cartoonito", "toonami", "baby tv", "jetix"]):
                  return "Kids"
              
              # Sports (single group)
              if any(kw in name_lower for kw in ["sports", "star sports", "sony six", "ten", "willow", "espn", "sports18", "cricket", "football", "jiofootball"]):
                  return "Sports"
              
              # Entertainment (Hindi + English series/reality)
              if any(kw in name_lower for kw in ["star plus", "colors", "sony sab", "zee tv", "&tv", "big magic", "rishtey", "shemaroo", "dangal tv", "sony pal", "zee anmol", "star utsav", "zee smile", "sony wah", "star world", "fox life", "axn", "comedy central", "mtv", "hbo", "universal tv", "paramount"]):
                  return "Entertainment"
              
              # Movies (Hindi + English films)
              if any(kw in name_lower for kw in ["zee cinema", "sony max", "star gold", "colors cineplex", "zee anmol cinema", "cineplex bollywood", "&pictures", "zee action", "goldmines", "b4u movies", "moviemax", "sony pix", "movies ok", "movies now", "star movies", "cinema world", "fox action movies"]):
                  return "Movies"
              
              # Hindi News
              if any(kw in name_lower for kw in ["aaj tak", "abp news", "india today", "news18", "republic bharat", "ndtv india", "times now", "zee news", "india tv", "cnn news18"]):
                  return "Hindi News"
              
              # English News
              if any(kw in name_lower for kw in ["bbc world", "cnn", "bloomberg", "cnbc", "fox news", "al jazeera"]):
                  return "English News"
              
              # Infotainment (renamed + moved Nat Geo, History HD, Discovery Science)
              if any(kw in name_lower for kw in ["discovery", "nat geo", "national geographic", "history", "history hd", "animal planet", "travelxp", "tlc", "discovery science"]):
                  return "Infotainment"
              
              # Music
              if any(kw in name_lower for kw in ["9xm", "mastiii", "mtv", "zoom", "bindass", "music india", "shemaroo umang"]):
                  return "Music"
              
              return "Others / General"

          lines = [
              "#EXTM3U",
              f"# Generated {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')} from {SOURCE_URL}",
              "# Excluded: Tamil/Telugu/Kannada/Gujarati/Malayalam/Punjabi/Bhojpuri/Marathi/DD/Devotional/Educational",
              "# Groups: Bengali, Assamese, Kids, Entertainment (Hindi+English series), Movies (Hindi+English films), Sports (single)"
          ]

          shared_cookie = None
          processed_count = 0

          for ch in channels:
              name = ch.get("name") or ch.get("title") or "Unknown"
              name_lower = name.lower()

              if any(pat in name_lower for pat in exclude_patterns):
                  continue

              logo   = ch.get("logo", "")
              link   = ch.get("link") or ch.get("url") or ch.get("stream") or ""
              drm    = ch.get("drmLicense") or ""
              cookie = ch.get("cookie") or ""

              if not link or not drm or ":" not in drm:
                  continue

              if cookie and not shared_cookie:
                  shared_cookie = cookie
              cookie = shared_cookie or cookie
              if not cookie:
                  continue

              kid, key = drm.split(':', 1)
              kid = kid.strip().replace('-', '')
              key = key.strip().replace('-', '')
              if len(kid) != 32 or len(key) != 32:
                  continue

              token_part = cookie.split("=", 1)[1] if "=" in cookie else ""

              category = get_category(name)

              lines.extend([
                  f'#EXTINF:-1 tvg-id="{name.replace(" ", "_")}" group-title="{category}" tvg-logo="{logo}",{name}',
                  "#KODIPROP:inputstream.adaptive.license_type=clearkey",
                  f"#KODIPROP:inputstream.adaptive.license_key=https://aqfadtv.xyz/clearkey/results.php?keyid={kid}&key={key}",
                  f"#EXTVLCOPT:http-user-agent={USER_AGENT}",
                  f'#EXTHTTP:{{"cookie":"{cookie}"}}',
                  f"{link}?__hdnea__={token_part}",
                  ""
              ])
              processed_count += 1

          if processed_count == 0:
              print("No channels after filtering")
              exit(1)

          m3u_content = "\n".join(lines)

          headers = {
              "Authorization": f"token {GIST_TOKEN}",
              "Accept": "application/vnd.github+json"
          }
          payload = {
              "files": {
                  OUTPUT_FILE_NAME: {"content": m3u_content}
              }
          }
          url = f"https://api.github.com/gists/{GIST_ID}"
          r = requests.patch(url, headers=headers, json=payload)

          if r.status_code == 200:
              raw = f"https://gist.githubusercontent.com/raw/{GIST_ID}/{OUTPUT_FILE_NAME}"
              print(f"Success! Updated Gist. Channels processed: {processed_count}")
              print(f"Raw URL: {raw}")
          else:
              print(f"Gist update failed ({r.status_code}): {r.text}")
              exit(1)
          EOF

      - name: Log completion
        run: echo "Workflow completed"
